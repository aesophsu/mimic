"""
ç”Ÿæˆ Table 1 åŸºçº¿ç‰¹å¾è¡¨ï¼ˆè®ºæ–‡è§„èŒƒç‰ˆï¼‰

æ”¹è¿›ï¼š
1. ç»“æ„åˆ†ç»„ï¼šDemographics, Severity Scores, Organ Support, Laboratory, Outcomes
2. SMD åˆ—ï¼šæ ‡å‡†åŒ–å‡æ•°å·®ï¼ŒSMD > 0.1 è¡¨ç¤ºå­˜åœ¨æ˜¾è‘—å·®å¼‚
3. å•ä½ç»Ÿä¸€ï¼šå®éªŒå®¤æŒ‡æ ‡é™„å•ä½
4. åˆ†ç±»å˜é‡åˆå¹¶ï¼šä»…æ˜¾ç¤º Male n(%) ç­‰é˜³æ€§ç±»åˆ«
5. å±•ç¤ºåè§„èŒƒï¼šMechanical ventilation, Creatinine ç­‰
6. eICU å¤–éƒ¨éªŒè¯åˆ—ï¼šå±•ç¤ºäººç¾¤æ¼‚ç§»

å‰ç½®ï¼š01_mimic_cleaningï¼ˆmimic_raw_scale.csvï¼‰ï¼›å®Œæ•´ Table 1 éœ€ 08_eicu_alignment_cleaningï¼ˆeicu_raw_scale.csvï¼‰ã€‚
run_all å…¨æµç¨‹æ—¶ 03 åœ¨ 08 ä¹‹åè¿è¡Œï¼›mimic-only æ—¶ 03 åœ¨ 02 ä¹‹åè¿è¡Œã€‚
"""
import os
import sys
import json
import numpy as np
import pandas as pd
from scipy import stats

sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))
from utils.feature_formatter import FeatureFormatter
from utils.study_config import OUTCOMES
from utils.paths import get_cleaned_path, get_external_path, get_artifact_path, get_main_table_dir, ensure_dirs
from utils.logger import log as _log, log_header
from utils.outcome_utils import normalize_gender
from utils.table1_config import (
    TABLE1_GROUPS,
    TABLE1_DISPLAY_OVERRIDES,
    TABLE1_UNITS,
    BINARY_SHOW_POSITIVE_ONLY,
    TABLE1_FOOTNOTES,
    TABLE1_USE_INDENT,
)

MIMIC_PATH = get_cleaned_path("mimic_raw_scale.csv")
EICU_PATH = get_external_path("eicu_raw_scale.csv")
DICT_PATH = get_artifact_path("features", "feature_dictionary.json")
TABLE_DIR = get_main_table_dir()
GROUPBY_COL = "pof"  # Non-POF (0) vs POF (1)


def _get_display_label(col, with_unit=True):
    """è·å– Table 1 å±•ç¤ºåï¼Œä¼˜å…ˆä½¿ç”¨è¦†ç›–é…ç½®"""
    override = TABLE1_DISPLAY_OVERRIDES.get(col)
    if override:
        label = override
    else:
        formatter = FeatureFormatter()
        label = formatter.get_label(col, with_unit=False)
    if with_unit and col in TABLE1_UNITS and TABLE1_UNITS[col]:
        unit = TABLE1_UNITS[col].replace("Ã—", "x").replace("â¹", "9")  # CSV å…¼å®¹
        label = f"{label} ({unit})"
    return label


def _smd_continuous(x0, x1):
    """è¿ç»­å˜é‡ SMD: (mean1 - mean0) / pooled_sd"""
    m0, m1 = x0.mean(), x1.mean()
    s0, s1 = x0.std(), x1.std()
    n0, n1 = len(x0.dropna()), len(x1.dropna())
    if n0 < 2 or n1 < 2:
        return np.nan
    pooled = np.sqrt(((n0 - 1) * s0**2 + (n1 - 1) * s1**2) / (n0 + n1 - 2))
    if pooled == 0:
        return 0.0
    return abs((m1 - m0) / pooled)


def _smd_binary(p0, p1, n0, n1):
    """äºŒåˆ†ç±» SMD: Cohen's h æˆ– (p1-p0)/sqrt(p*(1-p))"""
    if n0 == 0 or n1 == 0:
        return np.nan
    p_pool = (n0 * p0 + n1 * p1) / (n0 + n1)
    if p_pool <= 0 or p_pool >= 1:
        return 0.0
    denom = np.sqrt(p_pool * (1 - p_pool))
    if denom == 0:
        return 0.0
    return abs((p1 - p0) / denom)


def _format_smd(smd):
    """SMD å±•ç¤ºï¼š>0.1 æ˜¾ç¤ºæ•°å€¼ï¼Œå¦åˆ™ <0.1"""
    if np.isnan(smd):
        return "â€”"
    if smd < 0.1:
        return "<0.1"
    return f"{smd:.2f}"


def _median_iqr(series):
    """median [Q1, Q3]"""
    s = series.dropna()
    if s.empty:
        return "â€”"
    q1, med, q3 = s.quantile([0.25, 0.5, 0.75])
    return f"{med:.1f} [{q1:.1f}, {q3:.1f}]"


def _n_pct(n, total):
    return f"{n} ({100*n/total:.1f}%)" if total > 0 else "â€”"


def _pvalue_continuous(x0, x1):
    try:
        _, p = stats.kruskal(x0.dropna(), x1.dropna())
        return "<0.001" if p < 0.001 else f"{p:.3f}"
    except Exception:
        return "â€”"


def _pvalue_categorical(tab):
    try:
        _, p, _, _ = stats.chi2_contingency(tab)
        return "<0.001" if p < 0.001 else f"{p:.3f}"
    except Exception:
        return "â€”"


def build_mimic_table1(df_mimic):
    """æ„å»º MIMIC åˆ†ç»„åŸºçº¿è¡¨ï¼šOverall, Non-POF, POF, P-value, SMD (POF vs Non-POF)"""
    g0 = df_mimic[df_mimic[GROUPBY_COL] == 0]
    g1 = df_mimic[df_mimic[GROUPBY_COL] == 1]
    n0, n1 = len(g0), len(g1)
    n_total = n0 + n1

    rows = [{
        "Characteristic": "n",
        "Overall": str(n_total),
        "Non-POF": str(n0),
        "POF": str(n1),
        "P-value": "",
        "SMD (POF vs Non-POF)": "",
    }]
    for group_name, cols in TABLE1_GROUPS.items():
        rows.append({
            "Characteristic": group_name,
            "Overall": "",
            "Non-POF": "",
            "POF": "",
            "P-value": "",
            "SMD (POF vs Non-POF)": "",
        })
        for col in cols:
            if col not in df_mimic.columns:
                continue
            label = _get_display_label(col)
            # POF ä¸ºåˆ†ç»„å˜é‡ï¼šOverall æ˜¾ç¤ºå‘ç”Ÿç‡ï¼ŒNon-POF=0%, POF=100%
            if col == GROUPBY_COL:
                v_total = (df_mimic[col] == 1).sum()
                overall = _n_pct(v_total, n_total)
                non_pof = "0 (0.0%)"
                pof = _n_pct(n1, n1)  # 100%
                pval = "â€”"
                smd = np.nan
            elif col in BINARY_SHOW_POSITIVE_ONLY:
                v0 = (g0[col] == 1).sum()
                v1 = (g1[col] == 1).sum()
                v_total = (df_mimic[col] == 1).sum()
                overall = _n_pct(v_total, n_total)
                non_pof = _n_pct(v0, n0)
                pof = _n_pct(v1, n1)
                tab = np.array([[n0 - v0, v0], [n1 - v1, v1]])
                pval = _pvalue_categorical(tab)
                smd = _smd_binary(v0 / n0, v1 / n1, n0, n1)
            else:
                overall = _median_iqr(df_mimic[col])
                non_pof = _median_iqr(g0[col])
                pof = _median_iqr(g1[col])
                pval = _pvalue_continuous(g0[col], g1[col])
                smd = _smd_continuous(g0[col], g1[col])
            char_display = f"  {label}" if TABLE1_USE_INDENT else label
            rows.append({
                "Characteristic": char_display,
                "Overall": overall,
                "Non-POF": non_pof,
                "POF": pof,
                "P-value": pval,
                "SMD (POF vs Non-POF)": _format_smd(smd),
            })
    return pd.DataFrame(rows)


def _char_to_col(char, label_to_col):
    """Characteristic å¯èƒ½å¸¦ç¼©è¿›ï¼Œéœ€ strip ååŒ¹é…"""
    return label_to_col.get(char) or label_to_col.get(char.strip())


# eICU é¦–æ—¥å¹²é¢„åˆ—æ˜ å°„ï¼ˆä¸ MIMIC intime è‡³ intime+24h å¯¹é½ï¼Œç”¨äº Table 1 åŸºçº¿ï¼‰
EICU_DAY1_COL_MAP = {
    "mechanical_vent_flag": "mechanical_vent_flag_day1",
    "vaso_flag": "vaso_flag_day1",
}


def _build_eicu_column(df_table1, df_eicu):
    """æŒ‰ Table 1 è¡Œé¡ºåºæ„å»º eICU åˆ—ï¼›Organ Support ä½¿ç”¨é¦–æ—¥å¹²é¢„ï¼ˆä¸ MIMIC å¯¹é½ï¼‰"""
    eicu_n = len(df_eicu)
    label_to_col = {}
    for _, cols in TABLE1_GROUPS.items():
        for col in cols:
            label_to_col[_get_display_label(col)] = col

    eicu_vals = []
    for _, row in df_table1.iterrows():
        char = row["Characteristic"]
        if char == "n":
            eicu_vals.append(str(eicu_n))
        elif char in TABLE1_GROUPS:
            eicu_vals.append("")
        else:
            col_found = _char_to_col(char, label_to_col)
            if col_found is None:
                eicu_vals.append("â€”")
                continue
            # eICU åŸºçº¿å¹²é¢„ä½¿ç”¨é¦–æ—¥åˆ—ï¼ˆä¸ MIMIC intime+24h å¯¹é½ï¼‰
            eicu_col = EICU_DAY1_COL_MAP.get(col_found, col_found)
            if eicu_col not in df_eicu.columns:
                eicu_col = col_found
            if eicu_col not in df_eicu.columns:
                eicu_vals.append("â€”")
            elif col_found in BINARY_SHOW_POSITIVE_ONLY:
                v = (df_eicu[eicu_col] == 1).sum()
                eicu_vals.append(_n_pct(v, eicu_n))
            else:
                eicu_vals.append(_median_iqr(df_eicu[eicu_col]))
    return eicu_vals


def _build_smd_mimic_vs_eicu(df_table1, df_mimic, df_eicu):
    """æ„å»º SMD (MIMIC vs eICU) åˆ—ï¼šé‡åŒ–äººç¾¤æ¼‚ç§»ï¼›Organ Support ä½¿ç”¨ eICU é¦–æ—¥åˆ—"""
    label_to_col = {}
    for _, cols in TABLE1_GROUPS.items():
        for col in cols:
            label_to_col[_get_display_label(col)] = col

    n_mimic, n_eicu = len(df_mimic), len(df_eicu)
    smd_vals = []
    for _, row in df_table1.iterrows():
        char = row["Characteristic"]
        if char in ["n", ""] or char in TABLE1_GROUPS:
            smd_vals.append("")
            continue
        col = _char_to_col(char, label_to_col)
        if col is None:
            smd_vals.append("â€”")
            continue
        eicu_col = EICU_DAY1_COL_MAP.get(col, col)
        if eicu_col not in df_eicu.columns:
            eicu_col = col
        if eicu_col not in df_eicu.columns:
            smd_vals.append("â€”")
            continue
        if col in BINARY_SHOW_POSITIVE_ONLY:
            p_mimic = (df_mimic[col] == 1).mean()
            p_eicu = (df_eicu[eicu_col] == 1).mean()
            smd = _smd_binary(p_mimic, p_eicu, n_mimic, n_eicu)
        else:
            x_mimic = df_mimic[col].dropna()
            x_eicu = df_eicu[eicu_col].dropna()
            if len(x_mimic) < 2 or len(x_eicu) < 2:
                smd_vals.append("â€”")
                continue
            smd = _smd_continuous(x_mimic, x_eicu)
        smd_vals.append(_format_smd(smd))
    return smd_vals


def _add_footnotes(df_table1):
    """åœ¨è¡¨æ ¼åº•éƒ¨æ·»åŠ è„šæ³¨è¡Œ"""
    n_cols = len(df_table1.columns)
    footnote_rows = []
    for i, note in enumerate(TABLE1_FOOTNOTES):
        row = [""] * n_cols
        row[0] = f"Note {i+1}. {note}"
        footnote_rows.append(row)
    df_foot = pd.DataFrame(footnote_rows, columns=df_table1.columns)
    return pd.concat([df_table1, df_foot], ignore_index=True)


def build_table1_with_eicu(df_table1, df_mimic, df_eicu):
    """æ·»åŠ  eICU åˆ—ã€SMD (MIMIC vs eICU) åˆ—åŠè„šæ³¨"""
    if df_eicu is None or len(df_eicu) == 0:
        return _add_footnotes(df_table1)
    df_table1 = df_table1.copy()
    eicu_vals = _build_eicu_column(df_table1, df_eicu)
    df_table1.insert(4, "eICU (External Validation)", eicu_vals)
    smd_drift = _build_smd_mimic_vs_eicu(df_table1, df_mimic, df_eicu)
    df_table1["SMD (MIMIC vs eICU)"] = smd_drift
    return _add_footnotes(df_table1)


def main():
    log_header("ğŸš€ 03_table1_baseline: è®ºæ–‡è§„èŒƒç‰ˆ Table 1")

    if not os.path.exists(MIMIC_PATH):
        _log(f"MIMIC æ•°æ®ä¸å­˜åœ¨: {MIMIC_PATH}", "ERR")
        return

    df_mimic = pd.read_csv(MIMIC_PATH)

    # é¢„å¤„ç†ï¼šä¸ 03 ä¸€è‡´
    df_mimic = normalize_gender(df_mimic)
    if "creatinine_max" in df_mimic.columns and "chronic_kidney_disease" in df_mimic.columns:
        df_mimic["subgroup_no_renal"] = (
            (df_mimic["creatinine_max"] < 1.5) & (df_mimic["chronic_kidney_disease"] == 0)
        ).astype(int)

    if GROUPBY_COL not in df_mimic.columns:
        _log(f"åˆ†ç»„åˆ— {GROUPBY_COL} ä¸å­˜åœ¨", "ERR")
        return

    df_table1 = build_mimic_table1(df_mimic)

    # eICU åˆ—ã€SMD (MIMIC vs eICU)ã€è„šæ³¨ï¼ˆè‹¥å­˜åœ¨ eICUï¼‰
    df_eicu = None
    if os.path.exists(EICU_PATH):
        df_eicu = pd.read_csv(EICU_PATH)
        _log(f"å·²åŠ è½½ eICU æ•°æ® N={len(df_eicu)}ï¼Œæ·»åŠ å¤–éƒ¨éªŒè¯åˆ—ã€SMD (MIMIC vs eICU)ã€è„šæ³¨", "OK")
        df_table1 = build_table1_with_eicu(df_table1, df_mimic, df_eicu)
    else:
        _log("eICU æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤–éƒ¨éªŒè¯åˆ—ï¼ˆè¿è¡Œ 08 åå¯é‡æ–°ç”Ÿæˆï¼‰", "WARN")
        df_table1 = _add_footnotes(df_table1)

    ensure_dirs(TABLE_DIR)
    out_path = os.path.join(TABLE_DIR, "Table1_baseline.csv")
    df_table1.to_csv(out_path, index=False)
    _log(f"Table 1 å·²ä¿å­˜: {os.path.abspath(out_path)}", "OK")
    _log("ä¸‹ä¸€æ­¥: 04_mimic_stat_audit.py æˆ– 09_cross_cohort_audit.pyï¼ˆå…¨æµç¨‹æ—¶ 03 åœ¨ 08 åè¿è¡Œï¼‰", "INFO")


if __name__ == "__main__":
    main()
